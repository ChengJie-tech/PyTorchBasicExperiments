{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba6236fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T15:01:39.412945Z",
     "start_time": "2021-09-08T15:01:39.404004Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import numpy as np\\nimport torch\\nimport torch.nn as nn\\nimport torch.nn.functional as F\\nimport torch.optim as optim\\nfrom torchvision import datasets, transforms\\nprint (\"PyTorch Version:\", torch.__version__)'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "print (\"PyTorch Version:\", torch.__version__)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cc5438b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T15:01:39.420240Z",
     "start_time": "2021-09-08T15:01:39.415926Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mnist_data = datasets.MNIST(\"./mnist_data\", train=True, download=True,\\n                           transform=transforms.Compose([transforms.ToTensor()]))\\nmnist_data'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"mnist_data = datasets.MNIST(\"./mnist_data\", train=True, download=True,\n",
    "                           transform=transforms.Compose([transforms.ToTensor()]))\n",
    "mnist_data\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3559458",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T15:01:39.431284Z",
     "start_time": "2021-09-08T15:01:39.423024Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mnist_data[0][0].shape'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"mnist_data[0][0].shape\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd7dbb83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T15:01:39.440163Z",
     "start_time": "2021-09-08T15:01:39.433977Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data = [d[0].data.cpu().numpy() for d in mnist_data]\\nprint(np.mean(data), np.std(data))'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"data = [d[0].data.cpu().numpy() for d in mnist_data]\n",
    "print(np.mean(data), np.std(data))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18b6d604",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T15:01:39.451636Z",
     "start_time": "2021-09-08T15:01:39.442056Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\\nBATCH_SIZE = 32\\ntrain_loader = torch.utils.data.DataLoader(\\n    datasets.MNIST(\"./mnist_data\",\\n                   train=True,\\n                   download=True,\\n                   transform=transforms.Compose([transforms.ToTensor()]),\\n                   transforms.Normalize((0.13066062,), (0.30810776,))\\n                  ),\\n    batch_size=BATCH_SIZE,\\n    shuffle=True,\\n    num_workers=1,\\n    pin_memory=True\\n    )\\ntest_loader = torch.utils.data.DataLoader(\\n    datasets.MNIST(\"./mnist_data\",\\n                   train=False,\\n                   download=True,\\n                   transform=transforms.Compose([transforms.ToTensor()]),\\n                   transforms.Normalize((0.13066062,), (0.30810776,))\\n                  ),\\n    batch_size=BATCH_SIZE,\\n    shuffle=True,\\n    num_workers=1,\\n    pin_memory=True\\n    )\\n\\nlr = 0.01\\nmomentum = 0.5\\nmodel = Net().to(device)\\noptimizer = torch.optim.SGD(model.parameters, lr=lr, momentum=momentum)\\n\\nnum_epochs = 2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 32\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\"./mnist_data\",\n",
    "                   train=True,\n",
    "                   download=True,\n",
    "                   transform=transforms.Compose([transforms.ToTensor()]),\n",
    "                   transforms.Normalize((0.13066062,), (0.30810776,))\n",
    "                  ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=1,\n",
    "    pin_memory=True\n",
    "    )\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\"./mnist_data\",\n",
    "                   train=False,\n",
    "                   download=True,\n",
    "                   transform=transforms.Compose([transforms.ToTensor()]),\n",
    "                   transforms.Normalize((0.13066062,), (0.30810776,))\n",
    "                  ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=1,\n",
    "    pin_memory=True\n",
    "    )\n",
    "\n",
    "lr = 0.01\n",
    "momentum = 0.5\n",
    "model = Net().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters, lr=lr, momentum=momentum)\n",
    "\n",
    "num_epochs = 2\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f352af2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T15:01:40.480894Z",
     "start_time": "2021-09-08T15:01:39.453444Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 1.9.0+cu111\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import cv2\n",
    "print (\"PyTorch Version:\", torch.__version__)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f42c4872",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T15:01:40.487933Z",
     "start_time": "2021-09-08T15:01:40.483739Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = \"./hymenoptera_data\"\n",
    "model_name = \"resnet\"\n",
    "num_classes = 2\n",
    "batch_size = 32\n",
    "num_epochs = 15\n",
    "feature_extract = True\n",
    "\n",
    "input_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea3f5338",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T15:01:40.504546Z",
     "start_time": "2021-09-08T15:01:40.492784Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'all_imgs = datasets.ImageFolder(os.path.join(data_dir, \"train\"),transforms.Compose([\\n                    transforms.RandomResizedCrop(input_size),\\n                    transforms.RandomHorizontalFlip(p=0.5),\\n                    transforms.ToTensor()])\\n                    )\\ntrain_loader = torch.utils.data.DataLoader(all_imgs, batch_size=batch_size, shuffle=True, num_workers=2)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"all_imgs = datasets.ImageFolder(os.path.join(data_dir, \"train\"),transforms.Compose([\n",
    "                    transforms.RandomResizedCrop(input_size),\n",
    "                    transforms.RandomHorizontalFlip(p=0.5),\n",
    "                    transforms.ToTensor()])\n",
    "                    )\n",
    "train_loader = torch.utils.data.DataLoader(all_imgs, batch_size=batch_size, shuffle=True, num_workers=2)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b001a01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T15:01:40.522461Z",
     "start_time": "2021-09-08T15:01:40.506547Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "data_transforms = {\n",
    "    \"train\": transforms.Compose([\n",
    "                    transforms.RandomResizedCrop(input_size),\n",
    "                    transforms.RandomHorizontalFlip(p=0.5),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    \"val\": transforms.Compose([\n",
    "                    transforms.Resize(input_size),\n",
    "                    transforms.CenterCrop(input_size),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                         data_transforms[x]) for x in [\"train\", \"val\"]}\n",
    "\n",
    "dataloader_dict = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=4) for x in [\"train\", \"val\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bacfae5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T15:01:40.527161Z",
     "start_time": "2021-09-08T15:01:40.524477Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'img = next(iter(train_loader))[0]\\nimg.shape'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"img = next(iter(train_loader))[0]\n",
    "img.shape\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a360a9ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T15:01:40.549062Z",
     "start_time": "2021-09-08T15:01:40.530152Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unloader = transforms.ToPILImage()\\nplt.ion\\n\\nx = img[8]\\nplt.imshow(unloader(x.squeeze(0)))'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"unloader = transforms.ToPILImage()\n",
    "plt.ion\n",
    "\n",
    "x = img[8]\n",
    "plt.imshow(unloader(x.squeeze(0)))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb89e757",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T15:01:40.986472Z",
     "start_time": "2021-09-08T15:01:40.553471Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extract):\n",
    "    if feature_extract:\n",
    "        for para in model.parameters():\n",
    "            para.requires_grad = False\n",
    "\n",
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    if model_name == \"resnet\":\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # 更改fc层：1000->2\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "    else:\n",
    "        print(\"model not implemented\")\n",
    "        return None, None\n",
    "    return model_ft, input_size\n",
    "\n",
    "model_ft, input_size = initialize_model(model_name,\n",
    "                                       num_classes,\n",
    "                                       feature_extract,\n",
    "                                       use_pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab9a0a15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T15:01:40.999460Z",
     "start_time": "2021-09-08T15:01:40.988373Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14cef77d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T15:01:41.017520Z",
     "start_time": "2021-09-08T15:01:41.008923Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft.layer1[0].conv1.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d604b49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T15:01:41.037856Z",
     "start_time": "2021-09-08T15:01:41.028569Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft.fc.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0778ace",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T15:01:41.050123Z",
     "start_time": "2021-09-08T15:01:41.039616Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, dataloaders, loss_fn, optimizer, num_epochs):\n",
    "    best_acc = 0.\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    epoch_loss = 0.\n",
    "    epoch_correct = 0.\n",
    "    val_acc_history = []\n",
    "    for epoch in range(num_epochs):\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            running_loss = 0.\n",
    "            running_corrects = 0.\n",
    "            if phase == \"train\":\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            \n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                with torch.autograd.set_grad_enabled(phase==\"train\"):\n",
    "                    outputs = model(inputs) # [bsz, 2]\n",
    "                    loss = loss_fn(outputs, labels)\n",
    "                    \n",
    "                preds = outputs.argmax(dim=1)\n",
    "                if phase == \"train\":\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                running_loss += loss.item() * inputs.shape[0]\n",
    "                running_corrects += torch.sum(preds.view(-1) == labels.view(-1)).item()\n",
    "                \n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects / len(dataloaders[phase].dataset)\n",
    "            \n",
    "            print(\"Phase {} loss:{}, acc:{}\".format(phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            if phase == \"val\":\n",
    "                val_acc_history.append(epoch_acc)\n",
    "                if epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                    \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1c5d048",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T15:01:47.919331Z",
     "start_time": "2021-09-08T15:01:41.051762Z"
    }
   },
   "outputs": [],
   "source": [
    "model_ft = model_ft.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(filter(lambda p:p.requires_grad, model_ft.parameters()),\n",
    "                           lr=0.001,\n",
    "                           momentum=0.9)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d705668b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T15:04:24.426720Z",
     "start_time": "2021-09-08T15:02:45.712807Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase train loss:0.6399044580146914, acc:0.5614754098360656\n",
      "Phase val loss:0.4516520617054958, acc:0.8562091503267973\n",
      "Phase train loss:0.5220197659046923, acc:0.7131147540983607\n",
      "Phase val loss:0.34195033319635326, acc:0.9084967320261438\n",
      "Phase train loss:0.37192933774385295, acc:0.8565573770491803\n",
      "Phase val loss:0.27907954808933283, acc:0.9019607843137255\n",
      "Phase train loss:0.3484264338602785, acc:0.8688524590163934\n",
      "Phase val loss:0.244010944382038, acc:0.9411764705882353\n",
      "Phase train loss:0.28509413902876807, acc:0.8975409836065574\n",
      "Phase val loss:0.22908790282953798, acc:0.9281045751633987\n",
      "Phase train loss:0.2598586150857269, acc:0.9139344262295082\n",
      "Phase val loss:0.21317300726385677, acc:0.934640522875817\n",
      "Phase train loss:0.24431768084158662, acc:0.9139344262295082\n",
      "Phase val loss:0.20898831124399223, acc:0.9281045751633987\n",
      "Phase train loss:0.20896800570800655, acc:0.9344262295081968\n",
      "Phase val loss:0.19978281329659855, acc:0.9411764705882353\n",
      "Phase train loss:0.21704333238914364, acc:0.9221311475409836\n",
      "Phase val loss:0.1932118571077297, acc:0.9411764705882353\n",
      "Phase train loss:0.1958214840928062, acc:0.9467213114754098\n",
      "Phase val loss:0.20243014171232585, acc:0.9150326797385621\n",
      "Phase train loss:0.2039588855915382, acc:0.9344262295081968\n",
      "Phase val loss:0.18494486613990435, acc:0.9477124183006536\n",
      "Phase train loss:0.19787114589917856, acc:0.9221311475409836\n",
      "Phase val loss:0.18557370678077337, acc:0.934640522875817\n",
      "Phase train loss:0.2094288375533995, acc:0.9221311475409836\n",
      "Phase val loss:0.18026232456459718, acc:0.9477124183006536\n",
      "Phase train loss:0.15918977485328425, acc:0.9590163934426229\n",
      "Phase val loss:0.17815965258218106, acc:0.9411764705882353\n",
      "Phase train loss:0.1749802979289508, acc:0.9508196721311475\n",
      "Phase val loss:0.17570898345872468, acc:0.934640522875817\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "_, hist = train(model_ft, dataloader_dict, loss_fn, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fcc7ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
